{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import cvlib as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model\n",
    "model = load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0) #stream video. 0 denotes primary camera. if more cameras are present, 1 or 2 can be given.\n",
    "classes = ['woman','man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while cam.isOpened(): #this method returns true if video capture has been initialised\n",
    "    ret, frame = cam.read() #read frames. ret stores the bool value, confirming whether the frame is read right.\n",
    "    \n",
    "    #cvlib detect_face method detects the face in the image\n",
    "    face, confidence = cv.detect_face(frame)\n",
    "    \n",
    "    #looping through the faces\n",
    "    for index,f in enumerate(face):\n",
    "        startx,starty = f[0],f[1]  #startx and starty are x and y coordinates of bottom left vertex of the box.\n",
    "        endx,endy = f[2],f[3]     ##endx and endy are x and y coordinates of top right vertex of the box.\n",
    "        \n",
    "        #drawing a rectangle over the detected face\n",
    "        cv2.rectangle(frame, (startx,starty), (endx,endy), (0,255,0),2) #2 is the thickness of the rectangle here\n",
    "        \n",
    "        #cropping the detected face\n",
    "        face_crop = np.copy(frame[starty:endy, startx:endx])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #preprocessing the image for the model\n",
    "        face_crop = cv2.resize(face_crop, (80,80))\n",
    "        face_crop  = face_crop.astype(\"float\")/255.0\n",
    "        face_crop = img_to_array(face_crop)\n",
    "        face_crop = np.expand_dims(face_crop, axis =0)\n",
    "        \n",
    "        \n",
    "        verd = model.predict(face_crop)[0] #this gives an array with confidence of each class. confidence for woman at 0th index, and at 1, for man\n",
    "        idx = np.argmax(verd) #this gives \n",
    "        if idx==0:\n",
    "            label = 'woman'\n",
    "        else:\n",
    "            label = 'man'\n",
    "\n",
    "        label = \"{}: {:.2f}%\".format(label,verd[idx] * 100)\n",
    "        \n",
    "      \n",
    "        X = int((startx+endx)/2)\n",
    "        \n",
    "        cv2.putText(frame,label, (X,endy) , cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0),2)\n",
    "    \n",
    "    #displaying image\n",
    "    cv2.imshow(\"Detect\", frame)\n",
    "    \n",
    "    #pressing \"Q\" to stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "#release camera and destroy windows\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
